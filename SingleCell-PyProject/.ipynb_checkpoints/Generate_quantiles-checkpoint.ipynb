{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles_from_project(project_ID):\n",
    "    \n",
    "    # Check if percentil already exists\n",
    "    if os.path.exists(f'../SingleCell-Files/percentiles/{project_ID}.percentiles.csv'):\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Reading files for {project_ID}...\")\n",
    "    # Read project matrix and metadata\n",
    "    matrix, metadata, cell_names, gen_names = read_files(project_ID)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if matrix is None:\n",
    "        remove_project_files(project_ID)\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Getting cell type groups for {project_ID}...\")\n",
    "    # Generate cell type groups with metadata\n",
    "    cell_type_groups = get_cell_type_groups(metadata, cell_names)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Generating percentiles for {project_ID}...\")\n",
    "    # Get mean percentiles of each cell type\n",
    "    get_percentiles(matrix, cell_type_groups)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(f\"Percentiles created for {project_ID}!\")\n",
    "    \n",
    "    # Remove project files, we don't need them anymore\n",
    "    remove_project_files(project_ID)\n",
    "    \n",
    "    return cell_type_groups, gen_names['Gen_Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(project_ID):\n",
    "    # Download matrix using ontology link\n",
    "    download_matrix(project_ID)\n",
    "    \n",
    "    # Read matrix\n",
    "    matrix_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx'\n",
    "    matrix = mmread(matrix_file_name).transpose()\n",
    "    \n",
    "    # Read metadata\n",
    "    metadata = pd.read_csv(f'https://www.ebi.ac.uk/gxa/sc/experiment/{project_ID}/download?fileType=experiment-design&accessKey=', sep='\\t')\n",
    "    \n",
    "    if 'Sample Characteristic[cell type]' not in metadata.columns:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    metadata = metadata[['Assay', 'Sample Characteristic[cell type]']]\n",
    "    \n",
    "    # Read cell names\n",
    "    cells_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_cols'\n",
    "    cell_names = pd.read_csv(cells_file_name, header=None, names=['Assay'])\n",
    "    \n",
    "    # Read gen names\n",
    "    gens_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_rows'\n",
    "    gen_names = pd.read_csv(gens_file_name, header=None, names=['Gen_Name'])\n",
    "    \n",
    "    gen_names['Gen_Name'] = gen_names['Gen_Name'].apply(lambda x: x.split('\\t')[1])\n",
    "    \n",
    "    return matrix, metadata, cell_names, gen_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_matrix(project_ID):\n",
    "    \n",
    "    server_name = 'http://194.4.103.244:3030'\n",
    "    service_name = 'ds'\n",
    "    request_url = server_name + '/' + service_name\n",
    "    \n",
    "    path_to_links = '../SingleCell-Files/downloads/'\n",
    "    \n",
    "    query = '''\n",
    "        PREFIX a: <http://www.semanticweb.org/alicia/ontologies/2020/8/singleCellRepositories#> \n",
    "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        SELECT \n",
    "            ?normalisedCountsLink ?experimentDesignLink\n",
    "        WHERE\n",
    "        {\n",
    "        '''\\\n",
    "        + \\\n",
    "        f'''\n",
    "            ?projectID rdf:type a:Project ;\n",
    "                       a:PR.hasProjectID \"{project_ID}\" ;\n",
    "                       a:SPR.hasNormalisedCountsLink ?normalisedCountsLink ;\n",
    "                       a:SPR.hasExperimentDesignLink ?experimentDesignLink .\n",
    "        '''\\\n",
    "        +\\\n",
    "        '''      \n",
    "        }\n",
    "    '''\n",
    "    response = requests.post(request_url,\n",
    "       data={'query': query})\n",
    "    \n",
    "    if not response.json()['results']['bindings']:\n",
    "        return None\n",
    "    \n",
    "    normalisedCountsLink = response.json()['results']['bindings'][0]['normalisedCountsLink']['value'] \n",
    "    \n",
    "    # download the file contents in binary format\n",
    "    response = requests.get(normalisedCountsLink)\n",
    "    \n",
    "    zip_name = path_to_links + project_ID + \".zip\"\n",
    "    \n",
    "    # open method to open a file on your system and write the contents\n",
    "    with open(zip_name, \"wb\") as code:\n",
    "        code.write(response.content)\n",
    "        \n",
    "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "        zip_ref.extract(project_ID + '.aggregated_filtered_normalised_counts.mtx', path=path_to_links)\n",
    "        zip_ref.extract(project_ID + '.aggregated_filtered_normalised_counts.mtx_rows', path=path_to_links)\n",
    "        zip_ref.extract(project_ID + '.aggregated_filtered_normalised_counts.mtx_cols', path=path_to_links)\n",
    "        \n",
    "    os.remove(zip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_type_groups(metadata, cell_names):\n",
    "    # Merge both dataframes so we get the cells of the matrix with their corresponding type\n",
    "    cell_types = pd.merge(\n",
    "        cell_names,\n",
    "        metadata,\n",
    "        how=\"inner\",\n",
    "        on='Assay'\n",
    "    )\n",
    "    \n",
    "    # Group by cell type\n",
    "    grouped = cell_types.groupby(by='Sample Characteristic[cell type]')\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    # For each group, assign its name and the index of the matrix for this type\n",
    "    for name, group in grouped:\n",
    "        groups.append({\n",
    "            'name': name,\n",
    "            'index': group.index\n",
    "        })\n",
    "\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles(matrix, cell_type_groups):\n",
    "    for group in cell_type_groups:\n",
    "\n",
    "        print(group['name'])\n",
    "        submatrix = matrix.A[group['index']]\n",
    "        print(submatrix.shape)\n",
    "        mean = np.mean(submatrix, axis=0)\n",
    "                \n",
    "        group['percentiles'] = [percentileofscore(mean, x, 'strict') for x in mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_project_files(project_ID):\n",
    "    matrix_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx'\n",
    "    cells_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_cols'\n",
    "    gens_file_name = f'../SingleCell-Files/downloads/{project_ID}.aggregated_filtered_normalised_counts.mtx_rows'\n",
    "\n",
    "    os.remove(matrix_file_name)\n",
    "    os.remove(cells_file_name)\n",
    "    os.remove(gens_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test percentil creation with a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles created!\n",
      "CPU times: user 1.08 s, sys: 53.3 ms, total: 1.14 s\n",
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# groups, gen_names = get_percentiles_from_project('E-GEOD-100911')\n",
    "groups, gen_names = get_percentiles_from_project('E-MTAB-6386')\n",
    "# groups, gen_names = get_percentiles_from_project('E-GEOD-139324')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for d in [{'gen_name': gen_names}] + [{group['name']: group['percentiles']} for group in groups]:\n",
    "    dic.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen_name</th>\n",
       "      <th>leukocyte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>35.400328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>87.615272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>62.690683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>52.667414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000938</td>\n",
       "      <td>90.881669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23201</th>\n",
       "      <td>ENSG00000288529</td>\n",
       "      <td>4.369560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23202</th>\n",
       "      <td>ENSG00000288534</td>\n",
       "      <td>47.698871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23203</th>\n",
       "      <td>ENSG00000288550</td>\n",
       "      <td>55.494269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>ENSG00000288558</td>\n",
       "      <td>65.164182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23205</th>\n",
       "      <td>ENSG00000288564</td>\n",
       "      <td>34.361803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              gen_name  leukocyte\n",
       "0      ENSG00000000003  35.400328\n",
       "1      ENSG00000000419  87.615272\n",
       "2      ENSG00000000457  62.690683\n",
       "3      ENSG00000000460  52.667414\n",
       "4      ENSG00000000938  90.881669\n",
       "...                ...        ...\n",
       "23201  ENSG00000288529   4.369560\n",
       "23202  ENSG00000288534  47.698871\n",
       "23203  ENSG00000288550  55.494269\n",
       "23204  ENSG00000288558  65.164182\n",
       "23205  ENSG00000288564  34.361803\n",
       "\n",
       "[23206 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../SingleCell-Files/E-GEOD-100911.percentiles.csv', index=False)\n",
    "# df.to_csv('../SingleCell-Files/E-MTAB-6386.percentiles.csv', index=False)\n",
    "df.to_csv('../SingleCell-Files/E-GEOD-139324.percentiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pertenciles for all projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCEA projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get all SCEA projects from our ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name = 'http://194.4.103.244:3030'\n",
    "service_name = 'ds'\n",
    "request_url = server_name + '/' + service_name\n",
    "\n",
    "query = '''\n",
    "    PREFIX a: <http://www.semanticweb.org/alicia/ontologies/2020/8/singleCellRepositories#> \n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    SELECT \n",
    "        ?projectID\n",
    "    WHERE\n",
    "    {\n",
    "      ?project rdf:type a:Project ;\n",
    "               a:PR.hasProjectID ?projectID ;\n",
    "               a:SPR.isPartOfRepository \"SingleCellExpresionAtlas\" ;\n",
    "               a:SPR.hasCellType ?cellType .                                               \n",
    "    }\n",
    "\n",
    "    GROUP BY ?projectID\n",
    "'''\n",
    "\n",
    "response = requests.post(request_url,\n",
    "   data={'query': query})\n",
    "\n",
    "projects_IDs = []\n",
    "\n",
    "for project in response.json()['results']['bindings']:\n",
    "    project_ID = project['projectID']['value']\n",
    "    \n",
    "    projects_IDs.append(project_ID)\n",
    "\n",
    "len(projects_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the project IDs, we can get the percentile of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/159\n",
      "Reading files for E-ENAD-21...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8b076235c55d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_percentiles_from_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-aea79f01e8cd>\u001b[0m in \u001b[0;36mget_percentiles_from_project\u001b[0;34m(project_ID)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reading files for {project_ID}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Read project matrix and metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-14257574ceb8>\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(project_ID)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Read metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'https://www.ebi.ac.uk/gxa/sc/experiment/{project_ID}/download?fileType=experiment-design&accessKey='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'Sample Characteristic[cell type]'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         return IOArgs(\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mIncompleteRead\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdetect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/single-cell/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_projects = len(projects_IDs)\n",
    "\n",
    "for n, project_ID in enumerate(projects_IDs):\n",
    "    print(f\"{n+1}/{n_projects}\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    groups, gen_names = get_percentiles_from_project(project_ID)\n",
    "\n",
    "    if groups is None:\n",
    "        clear_output(wait=True)\n",
    "        continue\n",
    "    \n",
    "    dic = {}\n",
    "    for d in [{'gen_name': gen_names}] + [{group['name']: group['percentiles']} for group in groups]:\n",
    "        dic.update(d)\n",
    "    \n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv(f'../SingleCell-Files/percentiles/{project_ID}.percentiles.csv', index=False)\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the schema of the index. Each document will have a title and a content (project genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "\n",
    "schema = Schema(title=TEXT(stored=True), content=TEXT(stored=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the index in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import shutil\n",
    "\n",
    "path = \"../SingleCell-Files/index\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "else:\n",
    "    shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "ix = create_in(path, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ix.writer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test the index with 3 projects. 2 of them are studies of blood (E-MTAB-6386 and E-GEOD-139324). So they are suppose to have genes in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../SingleCell-Files/E-GEOD-100911.percentiles.csv')\n",
    "df1 = pd.read_csv('../SingleCell-Files/E-MTAB-6386.percentiles.csv')\n",
    "df2 = pd.read_csv('../SingleCell-Files/E-GEOD-139324.percentiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_genes = df0['gen_name'].tolist()\n",
    "df1_genes = df1['gen_name'].tolist()\n",
    "df2_genes = df2['gen_name'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the common gens between the projects, and some genes that are exclusive of each project. We will use these genes to test the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "['ENSG00000160695', 'ENSG00000162222', 'ENSG00000134864']\n",
      "['ENSDARG00000000001', 'ENSDARG00000000018', 'ENSDARG00000000019']\n",
      "['ENSG00000287846', 'ENSG00000284732', 'ENSG00000130528']\n",
      "['ENSG00000204572', 'ENSG00000181544', 'ENSG00000164185']\n"
     ]
    }
   ],
   "source": [
    "print(set(df0_genes).intersection(set(df1_genes)).intersection(set(df2_genes)))\n",
    "print(list(set(df1_genes).intersection(set(df2_genes)))[:3])\n",
    "print(df0_genes[:3])\n",
    "print(list(set(df1_genes).difference(set(df2_genes)))[:3])\n",
    "print(list(set(df2_genes).difference(set(df1_genes)))[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the three projects to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_document(title=\"E-GEOD-100911\", content=' '.join(df0_genes))\n",
    "writer.add_document(title=\"E-MTAB-6386\", content=' '.join(df1_genes))\n",
    "writer.add_document(title=\"E-GEOD-139324\", content=' '.join(df2_genes))\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do some test queries with the genes saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for gene ENSDARG00000034326\n",
      "CPU times: user 285 µs, sys: 18 µs, total: 303 µs\n",
      "Wall time: 298 µs\n",
      "E-GEOD-100911\n",
      "\n",
      "Searching for gene ENSG00000160695\n",
      "CPU times: user 288 µs, sys: 0 ns, total: 288 µs\n",
      "Wall time: 291 µs\n",
      "E-MTAB-6386\n",
      "E-GEOD-139324\n",
      "\n",
      "Searching for gene ENSG00000287846\n",
      "CPU times: user 250 µs, sys: 15 µs, total: 265 µs\n",
      "Wall time: 269 µs\n",
      "E-MTAB-6386\n",
      "\n",
      "Searching for gene ENSG00000204572\n",
      "CPU times: user 269 µs, sys: 0 ns, total: 269 µs\n",
      "Wall time: 273 µs\n",
      "E-GEOD-139324\n",
      "\n",
      "Searching for projects that contains genes starting with ENS\n",
      "CPU times: user 3.47 s, sys: 54.5 ms, total: 3.53 s\n",
      "Wall time: 3.53 s\n",
      "E-GEOD-100911\n",
      "E-MTAB-6386\n",
      "E-GEOD-139324\n"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "\n",
    "print(\"Searching for gene ENSDARG00000034326\")\n",
    "\n",
    "qp = QueryParser(\"content\", ix.schema)\n",
    "q = qp.parse(u\"ENSDARG00000000001\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "print()\n",
    "print(\"Searching for gene ENSG00000160695\")        \n",
    "\n",
    "q = qp.parse(u\"ENSG00000160695\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "print()\n",
    "print(\"Searching for gene ENSG00000287846\")        \n",
    "\n",
    "q = qp.parse(u\"ENSG00000287846\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "\n",
    "print()        \n",
    "print(\"Searching for gene ENSG00000204572\")        \n",
    "\n",
    "q = qp.parse(u\"ENSG00000204572\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])\n",
    "        \n",
    "print()\n",
    "print(\"Searching for projects that contains genes starting with ENS\")           \n",
    "\n",
    "q = qp.parse(u\"ENS*\")\n",
    "\n",
    "with ix.searcher() as s:\n",
    "    %time results = s.search(q, limit=None)\n",
    "    for result in results:\n",
    "        print(result['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "single-cell",
   "language": "python",
   "name": "single-cell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
